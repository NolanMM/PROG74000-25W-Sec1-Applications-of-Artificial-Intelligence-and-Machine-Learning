{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed89186e-35c6-4d79-ac9d-bf8f6cd39a9b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 30px; font-weight: bold;\">\n",
    "    Assignment/Lab 2: Winter 2025 Group 2\n",
    "    <br>***\n",
    "</div>\n",
    "\n",
    "<h1>Team members</h1>\n",
    "<b>\n",
    "    \n",
    "- Minh Le Nguyen\n",
    "- Liam Knapp\n",
    "- Gautam Singh\n",
    "- Gleb Ignatov\n",
    "\n",
    "</b>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: center; font-size: 24px; font-weight: bold;\">\n",
    "    Building Linear and Logistic Regression Models from Scratch\n",
    "</div>\n",
    "\n",
    "## I. Objectives\n",
    "\n",
    "<b>\n",
    "    \n",
    "- Implement Linear Regression and Logistic Regression from scratch without using machine learning \n",
    "libraries.  \n",
    "- Understand and apply gradient descent for optimizing model parameters. \n",
    "- Evaluate model performance using appropriate performance measures. \n",
    "- Use  your  implementation  to  perform  regression  and classification  on  the  datasets  provided  in  \n",
    "separate files. \n",
    "- Compare your custom implementations with scikit-learnâ€™s built-in models. \n",
    "- Reflect on challenges encountered and key takeaways from implementing regression models \n",
    "manually.\n",
    "    \n",
    "</b>\n",
    "\n",
    "**Note: Intructions Details at the bottoms**\n",
    "\n",
    "### *Formulas\n",
    "\n",
    "<b>\n",
    "\n",
    "1. [Linear Regression](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning#linear-models)\n",
    "\n",
    "2. [Logistic Regression](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning#linear-models)\n",
    "\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1740e4-53c1-45e4-aa7b-0ebfbacd9de2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## II. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e0deea-f4e4-4e12-bb5a-e66c31d0997d",
   "metadata": {},
   "source": [
    "### Set up your Python development environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "33296198-c46e-4a61-9e5f-553b93697740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\liamm\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\liamm\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\liamm\\anaconda3\\lib\\site-packages (1.11.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\liamm\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\liamm\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\liamm\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\liamm\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\liamm\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\liamm\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\liamm\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\liamm\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\liamm\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\liamm\\anaconda3\\lib\\site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\liamm\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\liamm\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcfd9c3f-8d39-4399-830b-f9aca0f38a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eca248f-3eb1-41b9-8f36-136da2a2de38",
   "metadata": {},
   "source": [
    "### Step 1: Implement the Linear Regression Algorithm        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5b712a4-5d29-481e-8834-bdd26e5d2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \"\"\"\n",
    "    A custom implementation of the LinearRegression algorithm for regression tasks.\n",
    "    \n",
    "    This class supports training on input features and corresponding target values, \n",
    "    and predicting target values for new input data.\n",
    "\n",
    "    Attributes:\n",
    "        TrainX (numpy.ndarray): Placeholder for training input features.\n",
    "        TrainY (numpy.ndarray): Placeholder for training target values.\n",
    "\n",
    "    Methods:\n",
    "        fit(x, y):\n",
    "            Trains the regressor using the provided input features (x) and target values (y).\n",
    "            Calculates the Slope and Intercept of the training data.\n",
    "        \n",
    "        predict(x):\n",
    "            Predicts target values for a given set of input features (x)\n",
    "            Returns the predictions as a numpy array.\n",
    "    \"\"\"\n",
    "    def fit(self, x, y):\n",
    "        self.TrainX = np.array(x)\n",
    "        self.TrainY = np.array(y)\n",
    "\n",
    "        # Compute means\n",
    "        xmean = np.mean(self.TrainX)\n",
    "        ymean = np.mean(self.TrainY)\n",
    "\n",
    "        # Compute numerator and denominator\n",
    "        numerator = sum((xi - xmean) * (yi - ymean) for xi, yi in zip(self.TrainX, self.TrainY))\n",
    "        denominator = sum((xi - xmean) ** 2 for xi in self.TrainX)\n",
    "\n",
    "        # Compute slope and intercept\n",
    "        self.slope = numerator / denominator\n",
    "        self.intercept = ymean - (self.slope * xmean)\n",
    "\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # The inputed target value to be predicted\n",
    "        x = np.array(x) \n",
    "        \n",
    "         # Used to store the predicted values for each targeted value point.\n",
    "        predictions = [] \n",
    "\n",
    "        # Loop through each element in the targeted value to predicted\n",
    "        for targetValue in x: \n",
    "            predictions.append(self.slope * targetValue + self.intercept)\n",
    "            \n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4a4f05-9538-4872-86a1-b74c63424d6a",
   "metadata": {},
   "source": [
    "### Stub to test KNN implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d47b12a4-9572-4c53-a6ac-0716a6934c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Y values: [85.59308315 76.83664459 68.08020603]\n"
     ]
    }
   ],
   "source": [
    "# Training data (features and target values)\n",
    "TrainX = [5, 7, 8, 7, 2, 17, 2, 9, 4, 11, 12, 9, 6]  # Training X values\n",
    "TrainY = [99, 86, 87, 88, 111, 86, 103, 87, 94, 78, 77, 85, 86]  # Training Y values\n",
    "\n",
    "# Test data\n",
    "test_x = [10, 15, 20]  # Test X values\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(TrainX, TrainY)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_x)\n",
    "print(\"Predicted Y values:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62ea93a-58ae-41ea-bbcd-eca9a329bae1",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset \n",
    "(training_dataset_linear.csv and validation_dataset_linear.csv)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e798b5c2-6123-4ebf-b619-8a2068faebb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Preview:\n",
      "       x       y\n",
      "0  1.730  72.851\n",
      "1  1.184  35.511\n",
      "2  0.169   0.525\n",
      "3  0.355   9.269\n",
      "4  0.250  13.250\n",
      "\n",
      "Validation Data Preview:\n",
      "       x       y\n",
      "0  2.443  89.705\n",
      "1  0.603  20.943\n",
      "2  1.137  38.205\n",
      "3  0.156  14.009\n",
      "4  0.163   8.761\n",
      "\n",
      "Training Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80 entries, 0 to 79\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x       80 non-null     float64\n",
      " 1   y       80 non-null     float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.4 KB\n",
      "None\n",
      "\n",
      "Validation Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x       20 non-null     float64\n",
      " 1   y       20 non-null     float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 452.0 bytes\n",
      "None\n",
      "\n",
      "Training Data Summary Statistics:\n",
      "               x          y\n",
      "count  80.000000  80.000000\n",
      "mean    0.821150  31.773212\n",
      "std     0.614088  22.473927\n",
      "min     0.001000   0.168000\n",
      "25%     0.311000  11.647000\n",
      "50%     0.650000  26.976000\n",
      "75%     1.233000  47.124500\n",
      "max     2.712000  83.594000\n",
      "\n",
      "Validation Data Summary Statistics:\n",
      "               x          y\n",
      "count  20.000000  20.000000\n",
      "mean    0.769650  29.834350\n",
      "std     0.657699  23.462392\n",
      "min     0.156000   5.554000\n",
      "25%     0.240250  10.718750\n",
      "50%     0.583000  23.298500\n",
      "75%     1.215250  38.953750\n",
      "max     2.443000  89.705000\n",
      "\n",
      "Missing Values in Training Data:\n",
      "x    0\n",
      "y    0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Validation Data:\n",
      "x    0\n",
      "y    0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate Rows in Training Data: 0\n",
      "Duplicate Rows in Validation Data: 0\n",
      "\n",
      "Training Data Types:\n",
      "x    float64\n",
      "y    float64\n",
      "dtype: object\n",
      "\n",
      "Validation Data Types:\n",
      "x    float64\n",
      "y    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "def step_2_load_dataset(file_path=\"dataset/training_dataset_linear.csv\", validation_file_path=\"dataset/validation_dataset_linear.csv\"):\n",
    "    \"\"\"\n",
    "    Load the dataset and display useful information about the dataset\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file containing the training dataset.\n",
    "        validation_file_path (str): Path to the CSV file containing the validation dataset.\n",
    "        \n",
    "    Returns:\n",
    "        trainData (DataFrame):  Pandas dataframe containing the training dataset.\n",
    "        validationData (DataFrame): Pandas dataframe containing the validation dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    trainData = pd.read_csv(file_path)\n",
    "    validationData = pd.read_csv(validation_file_path)\n",
    "\n",
    "    pd.reset_option('display.max_rows')\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.max_colwidth')\n",
    "\n",
    "    print(\"Training Data Preview:\")\n",
    "    print(trainData.head())\n",
    "    \n",
    "    print(\"\\nValidation Data Preview:\")\n",
    "    print(validationData.head())\n",
    "\n",
    "    print(\"\\nTraining Data Info:\")\n",
    "    print(trainData.info())\n",
    "    \n",
    "    print(\"\\nValidation Data Info:\")\n",
    "    print(validationData.info())\n",
    "    \n",
    "    print(\"\\nTraining Data Summary Statistics:\")\n",
    "    print(trainData.describe())\n",
    "    \n",
    "    print(\"\\nValidation Data Summary Statistics:\")\n",
    "    print(validationData.describe())\n",
    "\n",
    "    print(\"\\nMissing Values in Training Data:\")\n",
    "    print(trainData.isnull().sum())\n",
    "    \n",
    "    print(\"\\nMissing Values in Validation Data:\")\n",
    "    print(validationData.isnull().sum())\n",
    "\n",
    "    print(\"\\nDuplicate Rows in Training Data:\", trainData.duplicated().sum())\n",
    "    print(\"Duplicate Rows in Validation Data:\", validationData.duplicated().sum())\n",
    "\n",
    "    print(\"\\nTraining Data Types:\")\n",
    "    print(trainData.dtypes)\n",
    "    \n",
    "    print(\"\\nValidation Data Types:\")\n",
    "    print(validationData.dtypes)\n",
    "\n",
    "    return trainData, validationData\n",
    "\n",
    "Train_Data, Validation_Data = step_2_load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15ac9e3-92aa-4df8-ab21-04b51ad728e7",
   "metadata": {},
   "source": [
    "### Step 3: Train the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8115bb53-da35-4746-aa34-4082d9cc931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_3_train_linear_model(TrainData):\n",
    "    \"\"\"\n",
    "    Load the dataset, prepare the features and target values, and train a LinearRegression model.\n",
    "    \n",
    "    Args:\n",
    "        TrainData (pandas dataframe): Pandas dataframe containing the dataset.\n",
    "        \n",
    "    Returns:\n",
    "        linear_model (LinearRegression): Trained LinearRegression model.\n",
    "        TrainX (numpy.ndarray): Input features (Train x) used for training.\n",
    "        TrainY (numpy.ndarray): Target values (Train Y) used for training.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Separate the data into features (X) and target values (Y)\n",
    "    TrainX = TrainData[\"x\"].values.reshape(-1, 1)  # Convert to numpy array and reshape for the model\n",
    "    TrainY = TrainData[\"y\"].values  # Training Y values\n",
    "\n",
    "    # Instantiate the LinearRegression class\n",
    "    linear_model = LinearRegression()\n",
    "\n",
    "    # Fit the model with the training data\n",
    "    linear_model.fit(TrainX, TrainY)\n",
    "    \n",
    "    \n",
    "    return linear_model, TrainX, TrainY\n",
    "\n",
    "\n",
    "\n",
    "linear_model, TrainX, TrainY = step_3_train_linear_model(Train_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140bf250-f7d9-4356-84f4-1911d7b9b36d",
   "metadata": {},
   "source": [
    "### Step 4: Test and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1bc87a-c8e7-42e3-9f5a-16f4678f9b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bbbb230-610f-4477-b313-5ac7cad56855",
   "metadata": {},
   "source": [
    "### Step 5: Implement the Logistic Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a3048-eb09-466c-bdda-ea70c83684cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fba5f8c-cad9-4d1d-8db3-95a48837af03",
   "metadata": {},
   "source": [
    "### Step 6: Load the Dataset \n",
    "(training_dataset_logistic.csv and validation_dataset_logistic.csv)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e9f609-b775-4bb2-87e4-a1a3194f4bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10523734-e709-42e2-8a2a-4b6f5f86909f",
   "metadata": {},
   "source": [
    "### Step 7: Train the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9361a3a-89f4-4e67-b7a0-8dbd72e3b867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81d95083-e1c6-47b7-b30a-49fc3821b6e8",
   "metadata": {},
   "source": [
    "### Step 8: Test and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de86a0-0b1c-46ec-9291-ee4f0f0e7a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eab75c4c-d4dd-4e9c-b4ea-ac8796cabc09",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## III. Instructions\n",
    "\n",
    "### Step 1: Implement the Linear Regression Algorithm\n",
    "Your task is to implement the Linear Regression algorithm from scratch without using any machine \n",
    "learning libraries like scikit-learn for the core functionality. Follow these steps:\n",
    "\n",
    "<b>\n",
    "\n",
    "1. Create a LinearRegression class with the following methods:\n",
    "    - fit(X, y): Train the model using the given input features X and target values y.\n",
    "    - predict(X): Predict the target values for a given set of examples.\n",
    "    - You may add other methods or modify the input arguments as needed\n",
    "2. Use the Mean Squared Error (MSE) as the loss function\n",
    "3. Implement gradient descent to optimize the model parameters. Allow the learning rate (lr) and \n",
    "the number of iterations to be adjustable\n",
    "4. Ensure your implementation supports multiple features.\n",
    "\n",
    "</b>\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Load the Dataset \n",
    "\n",
    "You will receive files named training_dataset_linear.csv and validation_dataset_linear.csv containing the \n",
    "datasets. Perform the follow\n",
    "\n",
    "<b>\n",
    "\n",
    "1. Load the data from the provided CSV files.\n",
    "2. Understand the dataset using visualizations and basic statistical summaries.\n",
    "3. Preprocess the data if necessary (e.g., handle missing values, normalize features if needed). \n",
    "\n",
    "</b>\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Train the Linear Regression Model         \n",
    "\n",
    "<b>\n",
    "\n",
    "1. Initialize your LinearRegression model with a learning rate of lr and iter iterations. \n",
    "2. Train the model using the fit method with the provided training dataset.\n",
    "\n",
    "</b>\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4: Test and Evaluate the Model \n",
    "\n",
    "<b>\n",
    "\n",
    "1. Use the predict method to make predictions on the validation dataset.\n",
    "2. Compute the Mean Squared Error (MSE) and R-squared score to evaluate performance.\n",
    "3. Plot the regression line generated by the model along with the training data on a single graph.\n",
    "4. Compare your implementation with the result of LinearRegression from scikit-learn.\n",
    "\n",
    "</b>\n",
    "\n",
    "---\n",
    "\n",
    "### Step 5: Implement the Logistic Regression Algorithm  \n",
    "\n",
    "<b>\n",
    "\n",
    "1. Create a LogisticRegression class with the following methods:\n",
    "    - fit(X, y): Train the model using the given input features X and target values y. \n",
    "    - predict(X): Predict the class labels for a given set of examples. \n",
    "    - predict_proba(X): Return the probability scores for each class. \n",
    "    - You may add other methods or modify the input arguments as needed.\n",
    "\n",
    "2. Use the Binary Cross-Entropy (Log Loss) as the loss function.\n",
    "3. Implement gradient descent to optimize the model parameters. Allow the learning rate (lr) and \n",
    "the number of iterations to be adjustable.\n",
    "4. Ensure your implementation supports multiple features.\n",
    "5. Use the sigmoid function to map predictions to probabilities. \n",
    "   \n",
    "</b>\n",
    "\n",
    "---\n",
    "\n",
    "### Step 6: Load the Dataset    \n",
    "\n",
    "You will receive files named training_dataset_logistic.csv and validation_dataset_logistic.csv containing \n",
    "the datasets. Perform the following: \n",
    "\n",
    "<b>\n",
    "\n",
    "1. Load the data from the provided CSV files.\n",
    "2. Understand the dataset using visualizations and basic statistical summaries.\n",
    "3. Preprocess the data if necessary (e.g., handle missing values, normalize features if needed). \n",
    "\n",
    "</b>\n",
    "\n",
    "---\n",
    "\n",
    "### Step 7: Train the Logistic Regression Model        \n",
    "\n",
    "<b>\n",
    "\n",
    "1. Initialize your LogisticRegression model with a learning rate of lr and iter iterations.\n",
    "2. Train the model using the fit method with the provided training dataset.\n",
    "\n",
    "</b>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Step 8: Test and Evaluate the Model:\n",
    "\n",
    "<b>\n",
    "\n",
    "1. Use the predict method to classify examples from the validation dataset.\n",
    "2. Compute the accuracy, precision, recall, and F1-score to evaluate the model.\n",
    "3. Plot the decision boundary along with the training data on a single graph.\n",
    "4. What is the equation of the decision boundary?\n",
    "5. Compare your implementation with the result of LogisticRegression from scikit-learn.\n",
    "   \n",
    "</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
