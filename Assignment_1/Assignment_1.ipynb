{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3cbada3-b815-4b46-90dd-ba7ae8e36d62",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 30px; font-weight: bold;\">\n",
    "    Assignment/Lab 1: Winter 2025 Group 2\n",
    "    <br>***\n",
    "</div>\n",
    "\n",
    "<h1>Team members</h1>\n",
    "<b>\n",
    "    \n",
    "- Minh Le Nguyen\n",
    "- Liam Knapp\n",
    "- Gautam Singh\n",
    "- Gleb Ignatov\n",
    "\n",
    "</b>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: center; font-size: 24px; font-weight: bold;\">\n",
    "    Implementing and Testing the K-Nearest Neighbors (KNN) Model\n",
    "</div>\n",
    "\n",
    "## I. Objectives\n",
    "\n",
    "<b>\n",
    "    \n",
    "- Set up your Python development environment.\n",
    "- Get familiar with commonly used Python packages.\n",
    "- Implement the KNN algorithm from scratch.\n",
    "- Use your implementation to perform regression on the datasets provided in a separate file.\n",
    "- Evaluate the performance of your first machine learning algorithm.\n",
    "    \n",
    "</b>\n",
    "\n",
    "**Note: Intructions Details at the bottoms**\n",
    "\n",
    "### *Formulas\n",
    "\n",
    "<b>\n",
    "\n",
    "1. [KNN](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning#other)\n",
    "\n",
    "2. [Linear Regression](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning#linear-models)\n",
    "\n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59561dcd-2765-4b78-8179-7c36f64c520b",
   "metadata": {},
   "source": [
    "## II. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2f82a6-92e1-4d48-8735-4633cd053739",
   "metadata": {},
   "source": [
    "### Step 1: Set up your Python development environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1caf021d-f54a-4b32-92dd-bcc6010dfa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\liamm\\anaconda3\\envs\\aiclass\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\liamm\\anaconda3\\envs\\aiclass\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\liamm\\anaconda3\\envs\\aiclass\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\liamm\\anaconda3\\envs\\aiclass\\lib\\site-packages (1.15.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\liamm\\anaconda3\\envs\\aiclass\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\liamm\\anaconda3\\envs\\aiclass\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\liamm\\anaconda3\\envs\\aiclass\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\liamm\\anaconda3\\envs\\aiclass\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\liamm\\anaconda3\\envs\\aiclass\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\liamm\\anaconda3\\envs\\aiclass\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\liamm\\anaconda3\\envs\\aiclass\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\liamm\\anaconda3\\envs\\aiclass\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\liamm\\anaconda3\\envs\\aiclass\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\liamm\\anaconda3\\envs\\aiclass\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\liamm\\anaconda3\\envs\\aiclass\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\liamm\\anaconda3\\envs\\aiclass\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\liamm\\anaconda3\\envs\\aiclass\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\liamm\\anaconda3\\envs\\aiclass\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas matplotlib scipy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cac1f0fd-60eb-448b-986e-4cf11483df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from scipy.stats import randint\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fab039-004b-4c97-afbd-42a6728bf76b",
   "metadata": {},
   "source": [
    "### Step 2: Implement the KNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa4861e4-ff3f-4b0c-b1fc-3641df08a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNRegressor:\n",
    "     def __init__(self, k=3):\n",
    "        self.k = k # Set the K value for the predictions\n",
    "        self.TrainX = None # Place holder for training data\n",
    "        self.TrainY = None # Place holder for training data\n",
    "         \n",
    "     def fit(self, x, y):\n",
    "        # Train the algorithm for the given X and y. Where X: is the input features, y:  is the output.\n",
    "         self.TrainX = np.array(x) # Set / Save the training X values\n",
    "         self.TrainY = np.array(y) # Set / Save the training Y values\n",
    "\n",
    "     def predict(self, x):\n",
    "        # Predicts the target values for a given set of examples. \n",
    "\n",
    "        x = np.array(x) # The inputed target value to be predicted\n",
    "\n",
    "        predictions = [] # Used to store the predicted values for each targeted value point.\n",
    "         \n",
    "        for targetValue in x: # Loop through each element in the targeted value to be predicted\n",
    "            \n",
    "            #  Step 1: Calculate the Euclidean distance for each point in the training data.\n",
    "            EuclideanDistances = np.linalg.norm(self.TrainX - targetValue, axis=1)\n",
    "                # Subtracts the test point (targetValue) from each point in the training dataset (self.TrainX).\n",
    "                # np.linalg.norm computes the norm (distance) for each vector (row) in the matrix self.TrainX - targetValue.\n",
    "                # axis=1 means you calculate the norm row-wise (along the columns) which is needed for KNN algorithm.\n",
    "                # axis=0 means you calculate the norm column-wise (along the rows) which is not useful for KNN since we need the distance between points, not across features.\n",
    "    \n",
    "            # Step 2: Get the index's of (self.TrainX) in the training data set using the training points with the least distance.\n",
    "            NearestNeighboursIndex = np.argsort(EuclideanDistances)[:self.k] \n",
    "                # Sorts the array \"EuclideanDistances\" in ascending order (from smallest to largest).\n",
    "                # Used to find the Index of the training points with the smallest distance.\n",
    "                # Only selects the k number of training points specified.\n",
    "\n",
    "            # Step 3: Get the values for (self.TrainY) in the training dataset using the (self.TrainX) index from previous step.\n",
    "            NearestNeighbours = self.TrainY[NearestNeighboursIndex]\n",
    "                # Use the index from NearestNeighboursIndex to select the target values (self.TrainY) in the training data.\n",
    "                # By using this, we are selecting the target values (labels) that correspond to those nearest neighbors.\n",
    "\n",
    "            # Step 4: Average the values (labels) obtained from the previous step.\n",
    "            predictions.append(np.mean(NearestNeighbours))\n",
    "                # Computes the average of the target values for the nearest neighbors.\n",
    "                # The resulting prediction is then appended to the predictions list.\n",
    "         \n",
    "        # Return the KNearestNeighbour points\n",
    "        return np.array(predictions)\n",
    "         \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd8cdf21-cd50-48e8-a302-cae4b6e4c0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [2.5 7.5]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Training data (features and target values)\n",
    "    X_train = [[1, 2], [4, 6], [3, 5], [2, 1]]\n",
    "    y_train = [3, 8, 7, 2]\n",
    "    \n",
    "    # Test data\n",
    "    X_test = [[2, 3], [3, 4]]\n",
    "    \n",
    "    # Initialize and train the model\n",
    "    knn = KNNRegressor(k=2)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = knn.predict(X_test)\n",
    "    print(f\"Predictions: {predictions}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d60942-14ad-48c3-8eb6-137a95e9cbbc",
   "metadata": {},
   "source": [
    "### Step 3: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d8dd8c-7136-4e8d-83a8-abee5b4d440c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bea01e4a-ee58-41fe-b618-fd729468312b",
   "metadata": {},
   "source": [
    "### Step 4: Train the KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49155ea-6047-47d8-9cf8-c69d13c681a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dc2dfc8-9636-4a9e-95dc-02838ab3a86b",
   "metadata": {},
   "source": [
    "### Step 5: Test and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013739c-0720-43e6-8182-03aa26147bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca434805-6c01-47a2-be7b-d0e3ba5d0011",
   "metadata": {},
   "source": [
    "### Step 6: Answer the following questions:\n",
    "\n",
    "<b>\n",
    "\n",
    "- How does the choice of k affect the model's performance?\n",
    "- What challenges did you face while implementing the KNNRegressor algorithm?\n",
    "- How does the KNNRegressor algorithm handle noisy data?\n",
    "\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512ad171-3f07-47d2-b7d9-ea535e1abe1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d35e1fbb-642c-4066-ad76-e46bc074b52e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## III. Instructions\n",
    "\n",
    "### Step 1: Set up your Python development environment\n",
    "\n",
    "<b>\n",
    "\n",
    "1. Download and install Anaconda distribution platform\n",
    "2. Create a virtual environment and name it “aimlcourse”\n",
    "3. Install the following python packages:\n",
    "    - Data Manipulation and Analysis:\n",
    "        - NumPy: For numerical computing and handling multi-dimensional arrays.\n",
    "        - Pandas: For data manipulation and analysis with easy-to-use data structures like DataFrames.\n",
    "        - SciPy: A library for scientific computing with modules for optimization, integration, interpolation, and more.\n",
    "    - Data Visualization:\n",
    "        - Matplotlib: For creating static, interactive, and animated visualizations.\n",
    "    - Core Machine Learning Libraries:\n",
    "        - scikit-learn: A powerful library for traditional machine learning algorithms, preprocessing, and evaluation metrics. Includes tools for regression, classification, clustering, and dimensionality reduction.\n",
    "\n",
    "</b>\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Implement the KNN Algorithm (3 pts.)\n",
    "\n",
    "#### Implement the KNN algorithm from scratch without using any machine learning libraries like `scikit-learn` for the core functionality. Follow these steps:\n",
    "\n",
    "<b>\n",
    "\n",
    "1. Create a KNNRegressor class with the following methods:\n",
    "    - fit (X, y): Train the algorithm for the given X and y. Where X : is the input features, y: is the output.\n",
    "    - predict (X): Predicts the target values for a given set of examples.\n",
    "    - You should add other methods or modify the input arguments for the methods above as needed.\n",
    "2. In your implementation, you must set the Euclidean distance formula as the default method to compute distances between points.\n",
    "3. Return the average target value of the k nearest neighbors for regression.\n",
    "\n",
    "</b>\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Load the Dataset (0.5 pt.)\n",
    "#### Files named training_dataset_lab-1.csv and validation_dataset_lab-1.csv containing the datasets. Perform the following:\n",
    "\n",
    "<b>\n",
    "\n",
    "1. Load the data from the provided csv files.\n",
    "2. Ensure you understand the dataset before proceeding with your implementation. Use visualizations to gain better insights.\n",
    "3. Preprocess the data if necessary (e.g., handle missing values).\n",
    "\n",
    "</b>\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4: Train the KNN Model (0.5 pt.)\n",
    "\n",
    "<b>\n",
    "\n",
    "1. Initialize your KNNRegressor model with a value of k = 1.\n",
    "2. Train the KNNRegressor model using the `fit` method with the provided training dataset.\n",
    "\n",
    "</b>\n",
    "\n",
    "---\n",
    "\n",
    "### Step 5: Test and Evaluate the Model (3 pts.)\n",
    "\n",
    "<b>\n",
    "\n",
    "1. Use the `predict` method to predict target values for the validation dataset.\n",
    "2. Calculate the Root Mean Squared Error (RMSE) of your model.\n",
    "3. Experiment with different values of `k` and record the RMSE for each k and select the best k.\n",
    "4. Compare the nearest neighbour model (k =1) with the model which is corresponding to the best ‘k’ from step3. Use visualizations to gain better insights into the results.\n",
    "5. Compare the result of your KNNRegressor with the result of KNeighborsRegressor from scikit-learn. Use visualizations to gain better insights into the results.\n",
    "   \n",
    "</b>\n",
    "\n",
    "---\n",
    "\n",
    "### Step 6: Answer the following questions in your Jupyter notebook: (1.5 pts.)\n",
    "\n",
    "<b>\n",
    "\n",
    "1. How does the choice of k affect the model's performance?\n",
    "2. What challenges did you face while implementing the KNNRegressor algorithm?\n",
    "3. How does the KNNRegressor algorithm handle noisy data?\n",
    "   \n",
    "</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
